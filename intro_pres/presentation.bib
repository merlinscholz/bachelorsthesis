@InProceedings{Cordts_2016_CVPR,
	author = {Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
	title = {The Cityscapes Dataset for Semantic Urban Scene Understanding},
	booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016}
}
@inproceedings{kanezaki2018_unsupervised_segmentation,
	title={Unsupervised Image Segmentation by Backpropagation},
	author={Asako Kanezaki},
	booktitle={Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
	year={2018},
}
@ARTICLE{2016arXiv160100978C,
	author = {{Cohen}, Joseph Paul and {Lo}, Henry Z. and {Lu}, Tingting and
	{Ding}, Wei},
	title = "{Crater Detection via Convolutional Neural Networks}",
	journal = {arXiv e-prints},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	year = "2016",
	month = "Jan",
	eid = {arXiv:1601.00978},
	pages = {arXiv:1601.00978},
	archivePrefix = {arXiv},
	eprint = {1601.00978},
	primaryClass = {cs.CV},
	adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160100978C},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
},
@ARTICLE{ behnel2010cython,
	author={Behnel, S. and Bradshaw, R. and Citro, C. and Dalcin, L. and Seljebotn, D.S. and Smith, K.},
	journal={Computing in Science Engineering},
	title={Cython: The Best of Both Worlds},
	year={2011},
	month=march-april ,
	volume={13},
	number={2},
	pages={31 -39},
	keywords={Cython language;Fortran code;Python language extension;numerical loops;programming language;C language;numerical analysis;},
	doi={10.1109/MCSE.2010.118},
	ISSN={1521-9615},
},
@article{slic,
	title = {SLIC Superpixels},
	author = {Achanta, Radhakrishna and Shaji, Appu and Smith, Kevin and  Lucchi, Aurélien and Fua, Pascal and Süsstrunk, Sabine},
	address = {EPFL},
	pages = {15},
	year = {2010},
	abstract = {Superpixels are becoming increasingly popular for use in  computer vision applications. However, there are few  algorithms that output a desired number of regular, compact  superpixels with a low computational overhead. We introduce  a novel algorithm that clusters pixels in the combined  five-dimensional color and image plane space to efficiently  generate compact, nearly uniform superpixels. The  simplicity of our approach makes it extremely easy to use  -- a lone parameter specifies the number of superpixels --  and the efficiency of the algorithm makes it very  practical. Experiments show that our approach produces  superpixels at a lower computational cost while achieving a  segmentation quality equal to or greater than four  state-of-the-art methods, as measured by boundary recall  and under-segmentation error. We also demonstrate the  benefits of our superpixel approach in contrast to existing methods for two tasks in which superpixels have already  been shown to increase performance over pixel-based  methods.},
	url = {http://infoscience.epfl.ch/record/149300},
},
@inproceedings{Cordts2016Cityscapes,
	title={The Cityscapes Dataset for Semantic Urban Scene Understanding},
	author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
	booktitle={Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year={2016}
}
@inproceedings{LMBHPRDZ:ECCV:2014,
	title = {Microsoft {COCO}: Common Objects in Context},
	author = {Tsung-Yi Lin and Michael Maire and Serge Belongie and James Hays and Pietro Perona and Deva Ramanan and Piotr Doll{\'a}r and C. Lawrence Zitnick},
	booktitle = {European Conference on Computer Vision (ECCV)},
	year = {2014}
}
@article{mikevs2015benchmarking,
	title={Benchmarking of Remote Sensing Segmentation Methods},
	author={Mike{\v{s}}, Stanislav and Haindl, Michal and Scarpa, Giuseppe and Gaetano, Raffaele},
	journal={IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING},
	volume={8},
	number={5},
	year={2015}
},
@article{Bandeira2012,
	title={Detection of sub-kilometer craters in high resolution planetary images using shape and texture features},
	author={Bandeira, Louren{\c{c}}o and Ding, Wei and Stepinski, Tomasz F},
	journal={Advances in Space Research},
	volume={49},
	number={1},
	pages={64--74},
	year={2012},
	publisher={Elsevier}
},
@article{urbach2009automatic,
	title={Automatic detection of sub-km craters in high resolution planetary images},
	author={Urbach, Erik R and Stepinski, Tomasz F},
	journal={Planetary and Space Science},
	volume={57},
	number={7},
	pages={880--887},
	year={2009},
	publisher={Elsevier}
},
@article{umass_craters,
	title= {Crater Dataset},
	journal= {},
	author= {UMass Boston KDLab},
	year= {2013},
	url= {http://kdl.cs.umb.edu/w/datasets/craters/},
	abstract= {Dataset Objective:
	Determine if the instance is a crater or not a crater. 1=Crater, 0=Not Crater
	
	Data Set Information:
	This dataset was generated using HRSC nadir panchromatic image h0905_0000 taken by the Mars Express spacecraft. The images is located in the Xanthe Terra, centered on Nanedi Vallis and covers mostly Noachian terrain on Mars. The image had a resolution of 12.5 meters/pixel.
	
	Data Set Generation:
	
	Using the technique described by L. Bandeira (Bandeira, Ding, Stepinski. 2010.Automatic Detection of Sub-km Craters Using Shape and Texture Information) we identify crater candidates in the image using the pipeline depicted in the figure below. Each crater candidate image block is normalized to a standard scale of 48 pixels. Each of the nine kinds of image masks probes the normalized image block in four different scales of 12 pixels, 24 pixels, 36 pixels, and 48 pixels, with a step of a third of the mask size (meaning 2/3 overlap). We totally extract 1,090 Haar-like attributes using nine types of masks as the attribute vectors to represent each crater candidate.
	The dataset was converted to the Weka ARFF format by Joseph Paul Cohen in 2012.},
	keywords= {},
	terms= {}
},
@article{doi:10.1029/2006JE002808,
	author = {Malin, Michael C. and Bell III, James F. and Cantor, Bruce A. and Caplinger, Michael A. and Calvin, Wendy M. and Clancy, R. Todd and Edgett, Kenneth S. and Edwards, Lawrence and Haberle, Robert M. and James, Philip B. and Lee, Steven W. and Ravine, Michael A. and Thomas, Peter C. and Wolff, Michael J.},
	title = {Context Camera Investigation on board the Mars Reconnaissance Orbiter},
	journal = {Journal of Geophysical Research: Planets},
	volume = {112},
	number = {E5},
	pages = {},
	keywords = {Mars, spaceflight instruments, Mars Reconnaissance Orbiter},
	doi = {10.1029/2006JE002808},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2006JE002808},
	eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2006JE002808},
	abstract = {The Context Camera (CTX) on the Mars Reconnaissance Orbiter (MRO) is a Facility Instrument (i.e., government-furnished equipment operated by a science team not responsible for design and fabrication) designed, built, and operated by Malin Space Science Systems and the MRO Mars Color Imager team (MARCI). CTX will (1) provide context images for data acquired by other MRO instruments, (2) observe features of interest to NASA's Mars Exploration Program (e.g., candidate landing sites), and (3) conduct a scientific investigation, led by the MARCI team, of geologic, geomorphic, and meteorological processes on Mars. CTX consists of a digital electronics assembly; a 350 mm f/3.25 Schmidt-type telescope of catadioptric optical design with a 5.7° field of view, providing a ∼30-km-wide swath from ∼290 km altitude; and a 5000-element CCD with a band pass of 500–700 nm and 7 μm pixels, giving ∼6 m/pixel spatial resolution from MRO's nearly circular, nearly polar mapping orbit. Raw data are transferred to the MRO spacecraft flight computer for processing (e.g., data compression) before transmission to Earth. The ground data system and operations are based on 9 years of Mars Global Surveyor Mars Orbiter Camera on-orbit experience. CTX has been allocated 12\% of the total MRO data return, or about ≥3 terabits for the nominal mission. This data volume would cover ∼9\% of Mars at 6 m/pixel, but overlapping images (for stereo, mosaics, and observation of changes and meteorological events) will reduce this area. CTX acquired its first (instrument checkout) images of Mars on 24 March 2006.},
	year = {2007}
},
@misc{sheriff_2019,
	 title={The Martian Chronicles - When Deep Learning meets Global Collaboration},
	 url={https://towardsdatascience.com/the-martian-chronicles-when-deep-learning-meets-global-collaboration-872425ba2787},
	 journal={Medium},
	 publisher={Towards Data Science},
	 author={Sheriff, Samir},
	 year={2019},
	 month={Aug}
 } 
