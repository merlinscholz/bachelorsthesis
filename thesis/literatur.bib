% Encoding: UTF-8
@article{randindex,
	title={Natural scales in geographical patterns},
	author={Menezes, Telmo and Roth, Camille},
	journal={Scientific reports},
	volume={7},
	pages={45823},
	year={2017},
	publisher={Nature Publishing Group}
},

@InProceedings{kanezaki_18,
  author    = {Asako Kanezaki},
  title     = {Unsupervised Image Segmentation by Backpropagation},
  booktitle = {Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
  year      = {2018},
}
,

@Article{achanta_10,
  author   = {Achanta, Radhakrishna and Shaji, Appu and Smith, Kevin and Lucchi, Aurélien and Fua, Pascal and Süsstrunk, Sabine},
  title    = {SLIC superpixels},
  journal  = {Technical report, EPFL},
  year     = {2010},
  pages    = {15},
  month    = {06},
  abstract = {Superpixels are becoming increasingly popular for use in  computer vision applications. However, there are few  algorithms that output a desired number of regular, compact  superpixels with a low computational overhead. We introduce  a novel algorithm that clusters pixels in the combined  five-dimensional color and image plane space to efficiently  generate compact, nearly uniform superpixels. The  simplicity of our approach makes it extremely easy to use  -- a lone parameter specifies the number of superpixels --  and the efficiency of the algorithm makes it very  practical. Experiments show that our approach produces  superpixels at a lower computational cost while achieving a  segmentation quality equal to or greater than four  state-of-the-art methods, as measured by boundary recall  and under-segmentation error. We also demonstrate the  benefits of our superpixel approach in contrast to existing  methods for two tasks in which superpixels have already  been shown to increase performance over pixel-based  methods.},
}
,

@InProceedings{junyuan_16,
  author    = {Xie, Junyuan and Girshick, Ross and Farhadi, Ali},
  title     = {Unsupervised deep embedding for clustering analysis},
  booktitle = {International conference on machine learning},
  year      = {2016},
  pages     = {478--487},
}
,

@Article{bandeira_12,
  author   = {Lourenço Bandeira and Wei Ding and Tomasz F. Stepinski},
  title    = {Detection of sub-kilometer craters in high resolution planetary images using shape and texture features},
  journal  = {Advances in Space Research},
  year     = {2012},
  volume   = {49},
  number   = {1},
  pages    = {64 - 74},
  issn     = {0273-1177},
  abstract = {Counting craters is a paramount tool of planetary analysis because it provides relative dating of planetary surfaces. Dating surfaces with high spatial resolution requires counting a very large number of small, sub-kilometer size craters. Exhaustive manual surveys of such craters over extensive regions are impractical, sparking interest in designing crater detection algorithms (CDAs). As a part of our effort to design a CDA, which is robust and practical for planetary research analysis, we propose a crater detection approach that utilizes both shape and texture features to identify efficiently sub-kilometer craters in high resolution panchromatic images. First, a mathematical morphology-based shape analysis is used to identify regions in an image that may contain craters; only those regions – crater candidates – are the subject of further processing. Second, image texture features in combination with the boosting ensemble supervised learning algorithm are used to accurately classify previously identified candidates into craters and non-craters. The design of the proposed CDA is described and its performance is evaluated using a high resolution image of Mars for which sub-kilometer craters have been manually identified. The overall detection rate of the proposed CDA is 81%, the branching factor is 0.14, and the overall quality factor is 72%. This performance is a significant improvement over the previous CDA based exclusively on the shape features. The combination of performance level and computational efficiency offered by this CDA makes it attractive for practical application.},
  doi      = {10.1016/j.asr.2011.08.021},
  keywords = {Automatic crater detection, Pattern recognition, Craters, Mars},
  url      = {http://www.sciencedirect.com/science/article/pii/S027311771100617X},
}
,

@Misc{cohen_16,
  author        = {Joseph Paul Cohen and Henry Z. Lo and Tingting Lu and Wei Ding},
  title         = {Crater Detection via Convolutional Neural Networks},
  year          = {2016},
  archiveprefix = {arXiv},
  eprint        = {1601.00978},
  primaryclass  = {cs.CV},
}
,

@InBook{bildsegmentierung_14,
  chapter   = {Bildsegmentierung},
  pages     = {211--240},
  title     = {Bildverarbeitung und Objekterkennung},
  publisher = {Springer Fachmedien Wiesbaden},
  year      = {2014},
  author    = {S{\"u}{\ss}e, Herbert and Rodner, Erik},
  address   = {Wiesbaden},
  isbn      = {9783834826060},
  abstract  = {Die Bildsegmentierung ist wohl eines der wichtigsten Gebiete der Bildverarbeitung. Wenn Bilder analysiert bzw. Szenen klassifiziert werden, setzt das in der Regel eine korrekte Segmentierung voraus. Klassische Bildverarbeitungsalgorithmen laufen oft in folgenden Schritten ab: a)Daten- oder Bildeingabe,b)Vorverarbeitung der Bilder mit Bildverbesserungsalgorithmen, z. B. diverse Filter zur Rauschunterdr{\"u}ckung, Filter zur Beleuchtungskorrektur, Verst{\"a}rkung gewisser Eigenschaften, Detektion von „interessierenden`` Pixeln und vieles mehr,c)Segmentierung der Bilder in Regionen, Objekte mit geschlossenen Konturen oder Liniensegmente.d)Klassifikation und/oder Analyse der segmentierten Regionen, Objekte oder Liniensegmente.e)„Ausgabe`` der Analyseergebnisse.Die Trennung der Segmentierung (Punkt c) von der anschlie{\ss}enden Klassifikation (Punkt d) ist genaugenommen so streng gar nicht m{\"o}glich. Bei der Segmentierung klassifiziert man gew{\"o}hnlich schon etwas, ohne sich dessen bewusst zu sein.},
  booktitle = {Bildverarbeitung und Objekterkennung: Computer Vision in Industrie und Medizin},
  doi       = {10.1007/978-3-8348-2606-0_10},
  url       = {https://doi.org/10.1007/978-3-8348-2606-0_10},
}
,

@Misc{psa,
  title     = {Planetary Science Archive},
  journal   = {ESA},
  publisher = {ESA},
  url       = {https://archives.esac.esa.int/psa/},
}
,
@misc{isis,
	title={USGS Isis: Planetary Image Processing Software},
	url={https://isis.astrogeology.usgs.gov/index.html},
	journal={USGS Isis: Planetary Image Processing Software},
	publisher={United States Geological Survey},
	year={2019},
	month={Nov}
},
@book{gnuparallel,
	author       = {Tange, Ole},
	title        = {GNU Parallel 2018},
	publisher    = {Ole Tange},
	month        = Mar,
	year         = 2018,
	ISBN         = {9781387509881},
	doi          = {10.5281/zenodo.1146014},
	url          = {https://doi.org/10.5281/zenodo.1146014}
},

@Misc{hardesty_17,
  author    = {Hardesty, Larry},
  title     = {Explained: Neural networks},
  month     = {Apr},
  year      = {2017},
  journal   = {MIT News},
  publisher = {Massachusetts Institute of Technology},
  url       = {http://news.mit.edu/2017/explained-neural-networks-deep-learning-0414},
}
,

@Article{schmidhuber_15,
  author    = {Schmidhuber, J{\"u}rgen},
  title     = {Deep learning in neural networks: An overview},
  journal   = {Neural networks},
  year      = {2015},
  volume    = {61},
  pages     = {85--117},
  publisher = {Elsevier},
}
@article{urbach_stepinski_2009,
	title={Automatic detection of sub-km craters in high resolution planetary images},
	author={Urbach, Erik R and Stepinski, Tomasz F},
	journal={Planetary and Space Science},
	volume={57},
	number={7},
	pages={880--887},
	year={2009},
	publisher={Elsevier}
}

@InBook{hrsc,
  pages   = {15-74},
  title   = {HRSC: High resolution stereo camera},
  year    = {2009},
  author  = {Neukum, G. and Jaumann, R. and Basilevsky, Alexander and Dumke, A. and Gasselt, Stephan and Giese, B. and Hauber, E. and Head, James and Heipke, C. and Hoekzema, N. and Hoffmann, Harald and Greeley, R. and Gwinner, K. and Kirk, R.L. and Markiewicz, W. and Mccord, Thomas and Michael, G. and Muller, J.-P and Murray, J.B. and Associates, HRSC},
  month   = {06},
  isbn    = {978-92-9221-975-8},
  journal = {European Space Agency, (Special Publication) ESA SP},
}
@InProceedings{bandeira_10,
  author    = {{Bandeira}, L. and {Ding}, W. and {Stepinski}, T.~F.},
  title     = {{Automatic Detection of Sub-km Craters Using Shape and Texture Information}},
  booktitle = {Lunar and Planetary Science Conference},
  year      = {2010},
  series    = {Lunar and Planetary Science Conference},
  pages     = {1144},
  month     = {Mar},
  adsnote   = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl    = {https://ui.adsabs.harvard.edu/abs/2010LPI....41.1144B},
}

@Article{bandeira_07,
  author   = {L. {Bandeira} and J. {Saraiva} and P. {Pina}},
  title    = {Impact Crater Recognition on Mars Based on a Probability Volume Created by Template Matching},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  year     = {2007},
  volume   = {45},
  number   = {12},
  pages    = {4008-4015},
  month    = {Dec},
  issn     = {1558-0644},
  abstract = {This paper presents a methodology that brings together a number of techniques in the fields of image processing and pattern recognition with the purpose of achieving the automated detection of impact craters on images of planetary surfaces. The modular approach adopted for its development includes a phase of candidate selection, followed by template matching, in which the probability associated to each detection is established, and finally, by the analysis of the probability volume, in which the identification of craters on the image is achieved. It is tested on a set of images from four different regions of the surface of the planet Mars, all obtained by the same sensor in the last decade. The recognition rates for craters with radii that are larger than five pixels are very good, both globally and for each of the individual areas. The performance of the algorithm in the face of the variation of some of its parameters is analyzed and discussed in detail. We believe that this is a tool that is suitable for a general application in any area of a planet or satellite captured in an image, whatever the geomorphological setting, the optical sensor, and the conditions of illumination are.},
  doi      = {10.1109/TGRS.2007.904948},
  keywords = {image matching;Mars;meteorite craters;pattern recognition;planetary remote sensing;planetary surfaces;impact crater recognition;Mars;probability volume;template matching;image processing;pattern recognition;planetary surface;optical sensor;illumination;Mars;Planets;Image processing;Pattern recognition;Phase detection;Image analysis;Testing;Image sensors;Performance analysis;Algorithm design and analysis;Circular feature recognition;impact craters;Mars;template matching},
}

@Article{salamuniccar_10,
  author   = {G. {Salamuniccar} and S. {Loncaric}},
  title    = {Method for Crater Detection From Martian Digital Topography Data Using Gradient Value/Orientation, Morphometry, Vote Analysis, Slip Tuning, and Calibration},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  year     = {2010},
  volume   = {48},
  number   = {5},
  pages    = {2317-2329},
  month    = {May},
  issn     = {1558-0644},
  abstract = {Recently, all the craters from the major currently available manually assembled catalogs have been merged into the catalog with 57 633 known Martian impact craters. This paper presents a new crater detection algorithm (CDA) for the search of still uncataloged impact craters. The CDA is based on fuzzy edge detectors and Radon/Hough transform and utilizes digital topography data instead of image data. The critical parts of the method providing increased accuracy are as follows: (1) gradient-value/orientation-based techniques; (2) automated morphometry measurements of depth/diameter ratio, circularity, topographic cross-profile, rim, central peak, and radial range where the crater is preserved; (3) circularity analysis of votes in parameter space; (4) slip tuning of detected craters' parameters; and (5) calibration which partially compensates differences in morphology between small and large craters. Using the framework for the evaluation of CDAs, in comparison with prior work, the proposed detector shows the following: (1) significantly larger area under the free-response receiver operating characteristics (AUROC) and (2) significantly larger number of correct detections. Using the Mars Orbiter Laser Altimeter data as input, the CDA proposed numerous candidates for GT-57633 catalog extension. After the manual survey of all proposed craters and rejection of false detections, 57 592 impact craters were confirmed as correct detections. The accompanying result to the CDA is a new GT-115225 catalog.},
  doi      = {10.1109/TGRS.2009.2037750},
  keywords = {astronomical photometry;astronomical techniques;astronomy computing;Mars;meteorite craters;planetary remote sensing;planetary surfaces;Radon transforms;crater detection method;Martian digital topography data;gradient value;gradient orientation;morphometry;vote analysis;slip tuning;calibration;manually assembled catalogs;Martian impact craters;crater detection algorithm;uncataloged impact craters;fuzzy edge detectors;Radon transform;Hough transform;digital topography data;gradient-value technique;orientation-based technique;automated morphometry measurements;topographic cross-profile;circularity analysis;parameter space;free-response receiver operating characteristics;Mars Orbiter Laser Altimeter data;Surfaces;Voting;Calibration;Catalogs;Laser tuning;Image edge detection;Detectors;Extraterrestrial measurements;Assembly;Detection algorithms;Crater detection algorithms (CDAs);image edge analysis;Mars;object detection;Radon/Hough (RH) transform},
}

@Article{malin_07,
  author   = {Malin, Michael C. and Bell III, James F. and Cantor, Bruce A. and Caplinger, Michael A. and Calvin, Wendy M. and Clancy, R. Todd and Edgett, Kenneth S. and Edwards, Lawrence and Haberle, Robert M. and James, Philip B. and Lee, Steven W. and Ravine, Michael A. and Thomas, Peter C. and Wolff, Michael J.},
  title    = {Context Camera Investigation on board the Mars Reconnaissance Orbiter},
  journal  = {Journal of Geophysical Research: Planets},
  year     = {2007},
  volume   = {112},
  number   = {E5},
  abstract = {The Context Camera (CTX) on the Mars Reconnaissance Orbiter (MRO) is a Facility Instrument (i.e., government-furnished equipment operated by a science team not responsible for design and fabrication) designed, built, and operated by Malin Space Science Systems and the MRO Mars Color Imager team (MARCI). CTX will (1) provide context images for data acquired by other MRO instruments, (2) observe features of interest to NASA's Mars Exploration Program (e.g., candidate landing sites), and (3) conduct a scientific investigation, led by the MARCI team, of geologic, geomorphic, and meteorological processes on Mars. CTX consists of a digital electronics assembly; a 350 mm f/3.25 Schmidt-type telescope of catadioptric optical design with a 5.7° field of view, providing a ∼30-km-wide swath from ∼290 km altitude; and a 5000-element CCD with a band pass of 500–700 nm and 7 μm pixels, giving ∼6 m/pixel spatial resolution from MRO's nearly circular, nearly polar mapping orbit. Raw data are transferred to the MRO spacecraft flight computer for processing (e.g., data compression) before transmission to Earth. The ground data system and operations are based on 9 years of Mars Global Surveyor Mars Orbiter Camera on-orbit experience. CTX has been allocated 12\% of the total MRO data return, or about ≥3 terabits for the nominal mission. This data volume would cover ∼9\% of Mars at 6 m/pixel, but overlapping images (for stereo, mosaics, and observation of changes and meteorological events) will reduce this area. CTX acquired its first (instrument checkout) images of Mars on 24 March 2006.},
  doi      = {10.1029/2006JE002808},
  eprint   = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2006JE002808},
  keywords = {Mars, spaceflight instruments, Mars Reconnaissance Orbiter},
  url      = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2006JE002808},
}

@Misc{pds,
  title     = {MRO Imaging Node Mission Page},
  month     = {Jul},
  year      = {2019},
  journal   = {NASA},
  publisher = {NASA},
  url       = {https://pds-imaging.jpl.nasa.gov/portal/mro_mission.html},
}

@InProceedings{szegedy_15,
  author  = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  title   = {Going deeper with convolutions},
  year    = {2015},
  pages   = {1-9},
  month   = {06},
  doi     = {10.1109/CVPR.2015.7298594},
  journal = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
}

@Book{deeplearning_18,
  title     = {Deep learning with Python},
  publisher = {Manning Publications Co.},
  year      = {2018},
  author    = {Chollet Fran{\c{c}}ois},
  isbn      = {9781617294433},
}

@Book{thequest_09,
  title     = {The Quest for Artificial Intelligence},
  publisher = {Cambridge University Press},
  year      = {2009},
  author    = {Nilsson, Nils J.},
  doi       = {10.1017/CBO9780511819346},
  place     = {Cambridge},
}

@Book{deeplearning_16,
  title     = {Deep Learning},
  publisher = {MIT Press},
  year      = {2016},
  author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  note      = {\url{http://www.deeplearningbook.org}},
}

@Misc{cs231n,
  author = {Fei-Fei Li and Justin Johnson and Serena Yeung},
  title  = {Stanford Lecture Notes to: CS231n Convolutional Neural Networks for Visual Recognition},
  year   = {2019},
  url    = {http://cs231n.github.io/},
}

@Misc{brownlee_19,
  author  = {Brownlee, Jason},
  title   = {A Gentle Introduction to Pooling Layers for Convolutional Neural Networks},
  month   = {Jul},
  year    = {2019},
  journal = {Machine Learning Mastery},
  url     = {https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/},
}

@Misc{kizrak_19,
  author    = {Kızrak, Ayyüce},
  title     = {Comparison of Activation Functions for Deep Neural Networks},
  month     = {May},
  year      = {2019},
  journal   = {Medium},
  publisher = {Towards Data Science},
  url       = {https://towardsdatascience.com/comparison-of-activation-functions-for-deep-neural-networks-706ac4284c8a},
}

@Misc{geva,
  author  = {Geva},
  title   = {Fully Connected Layers in Convolutional Neural Networks: The Complete Guide},
  journal = {MissingLink.ai},
  url     = {https://missinglink.ai/guides/convolutional-neural-networks/fully-connected-layers-convolutional-neural-networks-complete-guide/},
}

@InBook{kaymak_19,
  pages     = {161--200},
  title     = {A Brief Survey and an Application of Semantic Image Segmentation for Autonomous Driving},
  publisher = {Springer International Publishing},
  year      = {2019},
  author    = {Kaymak, {\c{C}}a{\u{g}}r{\i} and U{\c{c}}ar, Ay{\c{s}}eg{\"u}l},
  editor    = {Balas, Valentina Emilia and Roy, Sanjiban Sekhar and Sharma, Dharmendra and Samui, Pijush},
  address   = {Cham},
  isbn      = {978-3-030-11479-4},
  abstract  = {Deep learning is a fast-growing machine learning approach to perceive and understand large amounts of data. In this paper, general information about the deep learning approach which is attracted much attention in the field of machine learning is given in recent years and an application about semantic image segmentation is carried out in order to help autonomous driving of autonomous vehicles. This application is implemented with Fully Convolutional Network (FCN) architectures obtained by modifying the Convolutional Neural Network (CNN) architectures based on deep learning. Experimental studies for the application are utilized 4 different FCN architectures named FCN-AlexNet, FCN-8s, FCN-16s and FCN-32s. For the experimental studies, FCNs are first trained separately and validation accuracies of these trained network models on the used dataset is compared. In addition, image segmentation inferences are visualized to take account of how precisely FCN architectures can segment objects.},
  booktitle = {Handbook of Deep Learning Applications},
  doi       = {10.1007/978-3-030-11479-4_9},
  url       = {https://doi.org/10.1007/978-3-030-11479-4_9},
}
@InProceedings{bsd500,
	author = {D. Martin and C. Fowlkes and D. Tal and J. Malik},
	title = {A Database of Human Segmented Natural Images and its
	Application to Evaluating Segmentation Algorithms and
	Measuring Ecological Statistics},
	booktitle = {Proc. 8th Int'l Conf. Computer Vision},
	year = {2001},
	month = {July},
	volume = {2},
	pages = {416--423}
}
@misc{bias,
	title={Neural Network Bias: Bias Neuron, Overfitting and Underfitting},
	url={https://missinglink.ai/guides/neural-network-concepts/neural-network-bias-bias-neuron-overfitting-underfitting/},
	journal={MissingLink.ai}
}

@misc{mariner4,
	title={Mariner 4},
	url={https://www.jpl.nasa.gov/missions/mariner-4/},
	journal={NASA},
	publisher={NASA}
}
@book{greeley_13,
	place={Cambridge},
	title={Introduction to Planetary Geomorphology},
	DOI={10.1017/CBO9781139020961},
	publisher={Cambridge University Press},
	author={Greeley, Ronald},
	year={2013}
}
@online{mola,
	author={NASA},
	title   = {Mars topography (MOLA dataset) HiRes},
	year    = {2000},
	month = {October}
	url={https://commons.wikimedia.org/wiki/File:Mars_topography_(MOLA_dataset)_HiRes.jpg}
}
@article{jain_91,
	title = "Unsupervised texture segmentation using Gabor filters",
	journal = "Pattern Recognition",
	volume = "24",
	number = "12",
	pages = "1167 - 1186",
	year = "1991",
	issn = "0031-3203",
	doi = "https://doi.org/10.1016/0031-3203(91)90143-S",
	url = "http://www.sciencedirect.com/science/article/pii/003132039190143S",
	author = "Anil K. Jain and Farshid Farrokhnia",
	keywords = "Texture segmentation, Multi-channel filtering, Gabor filters, Wavelet transform, Clustering, Clustering index",
	abstract = "This paper presents a texture segmentation algorithm inspired by the multi-channel filtering theory for visual information processing in the early stages of human visual system. The channels are characterized by a bank of Gabor filters that nearly uniformly covers the spatial-frequency domain, and a systematic filter selection scheme is proposed, which is based on reconstruction of the input image from the filtered images. Texture features are obtained by subjecting each (selected) filtered image to a nonlinear transformation and computing a measure of “energy” in a window around each pixel. A square-error clustering algorithm is then used to integrate the feature images and produce a segmentation. A simple procedure to incorporate spatial information in the clustering process is proposed. A relative index is used to estimate the “true” number of texture categories."
}
@misc{mathworks_15,
	title={Texture Segmentation Using Gabor Filters},
	url={https://mathworks.com/help/images/texture-segmentation-using-gabor-filters.html},
	journal={Texture Segmentation Using Gabor Filters - MATLAB & Simulink},
	publisher={MathWorks},
	year={2015}
}
@misc{nielsen_15,
	title={Neural Networks and Deep Learning},
	url={http://neuralnetworksanddeeplearning.com/},
	journal={Neural networks and deep learning},
	publisher={Determination Press},
	author={Nielsen, Michael A.},
	year={2015},
	month={Dec}
} 

@article{alexnet,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey},
	year = {2012},
	month = {01},
	pages = {},
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	volume = {25},
	journal = {Neural Information Processing Systems},
	doi = {10.1145/3065386}
}
@misc{kathuria_18,
	title={Intro to optimization in deep learning: Gradient Descent},
	url={https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/},
	journal={Paperspace Blog},
	publisher={Paperspace Blog},
	author={Kathuria, Ayoosh},
	year={2018},
	month={Jun}
} 
@article{berniker_15,
	author = {Berniker, Max and Kording, Konrad},
	year = {2015},
	month = {03},
	pages = {32},
	title = {Deep networks for motor control functions},
	volume = {9},
	journal = {Frontiers in computational neuroscience},
	doi = {10.3389/fncom.2015.00032}
}
@misc{visgeo,
	title={Texture Classification - Filters},
	url={https://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html},
	journal={Visual Geometry Group - University of Oxford},
	publisher={University of Oxford}
}
@article{leung_01,
	author = {Leung, Thomas and Malik, Jitendra},
	year = {2001},
	month = {06},
	pages = {29-44},
	title = {Representing and Recognizing the Visual Appearance of Materials using Three-dimensional Textons},
	volume = {43},
	journal = {International Journal of Computer Vision},
	doi = {10.1023/A:1011126920638}
}
@inproceedings{schmid_01,
	author = {Schmid, Cordelia},
	year = {2001},
	month = {02},
	pages = {II-39},
	title = {Constructing models for content-based image retrieval},
	volume = {2},
	isbn = {0-7695-1272-0},
	journal = {Proc CVPR},
	doi = {10.1109/CVPR.2001.990922}
}

@article{ioffe_15,
	title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
	author={Ioffe, Sergey and Szegedy, Christian},
	journal={arXiv preprint arXiv:1502.03167},
	year={2015}
}

@inproceedings{santurkar_18,
	title={How does batch normalization help optimization?},
	author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
	booktitle={Advances in Neural Information Processing Systems},
	pages={2483--2493},
	year={2018}
}

@article{menezes_17,
	title={Natural scales in geographical patterns},
	author={Menezes, Telmo and Roth, Camille},
	journal={Scientific reports},
	volume={7},
	pages={45823},
	year={2017},
	publisher={Nature Publishing Group}
}

@article{hubert_85,
	title={Comparing partitions},
	author={Hubert, Lawrence and Arabie, Phipps},
	journal={Journal of classification},
	volume={2},
	number={1},
	pages={193--218},
	year={1985},
	publisher={Springer}
}

@inproceedings{lin_14,
	title={Microsoft coco: Common objects in context},
	author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
	booktitle={European conference on computer vision},
	pages={740--755},
	year={2014},
	organization={Springer}
}

@article{arbelaez_10,
	title={Contour detection and hierarchical image segmentation},
	author={Arbelaez, Pablo and Maire, Michael and Fowlkes, Charless and Malik, Jitendra},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={33},
	number={5},
	pages={898--916},
	year={2010},
	publisher={IEEE}
}
@article{xia_17,
	title={W-net: A deep model for fully unsupervised image segmentation},
	author={Xia, Xide and Kulis, Brian},
	journal={arXiv preprint arXiv:1711.08506},
	year={2017}
}

@InProceedings{meil_03,
	author="Meil{\u{a}}, Marina",
	editor="Sch{\"o}lkopf, Bernhard
	and Warmuth, Manfred K.",
	title="Comparing Clusterings by the Variation of Information",
	booktitle="Learning Theory and Kernel Machines",
	year="2003",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="173--187",
	abstract="This paper proposes an information theoretic criterion for comparing two partitions, or clusterings, of the same data set. The criterion, called variation of information (VI), measures the amount of information lost and gained in changing from clustering {\$}{\{}{\backslash}cal C{\}}{\$}to clustering {\$}{\{}{\backslash}cal C{\}}'{\$}. The criterion makes no assumptions about how the clusterings were generated and applies to both soft and hard clusterings. The basic properties of VI are presented and discussed from the point of view of comparing clusterings. In particular, the VI is positive, symmetric and obeys the triangle inequality. Thus, surprisingly enough, it is a true metric on the space of clusterings.",
	isbn="978-3-540-45167-9"
}



@Comment{jabref-meta: databaseType:bibtex;}

