\chapter{Verwandte Arbeiten}
\label{chap:verwarbeiten}

\section{Bildsegmentierung}
\label{sec:segmentation}

\subsection{Unbeaufsichtigte Bildsegmentierung durch Backpropagation}
\label{ssec:kanezaki}
In \cite{kanezaki_18} wird ein Ansatz beschrieben, Convolutional Neural Networks zur Bildsegmentierung zu nutzen. Die Besonderheit an diesem Ansatz ist allerdings, dass er nicht wie frühere Versuche CNNs zur Bildsegmentierung zu nutzen auf überwachtem Lernen basiert, sondern unüberwachtes Lernen nutzt.

Dieser Ansatz erstellt eine Mapping-Funktion $c_n=f(x_n)$, die jedem der $N$ $p$-dimensionalen Pixel mit dem Merkmalsvektor $\{x_n\in\mathbb{R}^p\}_{n=1}^N$ eines Eingabebildes ein Clusterlabel $c$ mit $\{c_n\in\mathbb{Z}\}_{n=1}^N$ zuordnet.

Während das Ziel das gleiche wie bei überwachtem Lernen ist, wird hier weder eine Ground Truth, noch ein vorher angelerntes Neuronales Netz benötigt.

Erreicht wird dieses Ziel durch einen iterativen Prozess, in welchem ein anfangs untrainiertes neuronales Netz eine Bildsegmentierung erzeugt, welche anschließend mithilfe einer im Vorhinein erstellten, konstanten Segmentierung optimiert wird. Diese Segmentierung wird in diesem Paper über den SLIC-Algorithmus \cite{achanta_10} erzeugt. Der gesamte Algorithmus ist in \figurename~\ref{fig:Kan18_01} dargestellt. 

\begin{figure}[h]
	\centering
	\includegraphics[width=.8\textwidth,keepaspectratio]{images/Kan18_01.png}
	\caption{Vorgehensweise nach Kanezaki, aus \cite{kanezaki_18}}
	\label{fig:Kan18_01}
\end{figure}

\section{Unsupervised Deep Embedding for Clustering Analysis}
\label{sec:unsupervised_dec}
\cite{junyuan_16}

\section{Kratererkennung} % TODO Reread
\label{sec:craterdetection}

In \cite{bandeira_10} und dessen Fortsetzung \cite{bandeira_12} wird ein neuer Ansatz zur Kratererkennung vorgestellt. Zuvor wurden diese meist manuell katalogisiert, dies resultierte darin, dass nur die größten Krater dokumentiert wurden, oder darin, dass nur vergleichsweise kleine Bereiche innerhalb eines akzeptablen Zeitraums verarbeitet werden konnten. Daher legen die Autoren insbesondere Wert auf die korrekte Erkennung von kleineren Kratern.

Die erarbeitete Vorgehensweise beginnt damit, dass über einen möglichst effizienten Algorithmus (hier der Algorithmus von Urbach \etal \cite{urbach_stepinski_2009}) eine Vorsortierung von Krater-Kandidaten berechnet wird. Als Alternative zu diesem Algorithmus werden \cite{bandeira_07} und \cite{salamuniccar_10} genannt.

Der genutzte Algorithmus ist zwar relativ effizient, da er parallel alle Merkmale eliminiert, die nicht auf Krater hindeuten. Frühere Algorithmen hingegen griffen meist auf eine Brute-Force-Methode zurück. Zur Erkennung von Krater (\bzw Krater-Kandidaten) wird hier die Tatsache genutzt, dass diese auf Abbildungen meisten aus nebeneinander liegenden, starken Schatten- und Hightlight-Regionen bestehen.

Nach dieser Vorsortierung und Pre-Processing Schritten (in Form von Histogramm-Optimierung) werden in \cite{bandeira_10, bandeira_12} neun Bitmasken (siehe \figurename~\ref{fig:BDS12_01}) in verschiedenen Positionen, Größen und Ausrichtungen über die Kandidaten gelegt. Die Wahrscheinlichkeit, dass der Kandidat ein Krater ist, berechnet sich aus der Übereinstimmung zwischen den Bitmasken und dem eigentlichen Kandidatenbild. Abschließend werden die Ergebnisse mithilfe eines angepassten AdaBoost Algorithmus optimiert. Das Post-Processing besteht aus der Eliminierung von ungewöhnlich geformten Kratern.

\begin{figure}[h]
	\centering
	\includegraphics[width=.8\textwidth,keepaspectratio]{images/BDS12_01.png}
	\caption{Die neun, zur Merkmalsextrahierung genutzen Bitmasken, aus \cite{bandeira_12}}
	\label{fig:BDS12_01}
\end{figure}

In \figurename~\ref{fig:BDS12_02} sind die von AdaBoost ausgewählten, am stärksten gewichteten Bitmasken-Überlagerungen dargestellt. Es ist zu beachten, dass der Krater im Hintergrund nur ein Beispiel ist, und nicht alle Krater, die von den jeweiligen Bitmasken überlagert werden, darstellt.

\begin{figure}[H]
	\centering
	\includegraphics[width=.5\textwidth,keepaspectratio]{images/BDS12_02.png}
	\caption{Die sechs am stärksten gewichteten Bitmasken, aus \cite{bandeira_12}}
	\label{fig:BDS12_02}
\end{figure}

\subsection{Kratererkennung über Neuronale Netze}
\label{ssec:crater_cnn}
Auf der Basis des erwähnten, automatisch generierten Marskrater-Datensatz, wird in \cite{cohen_16} ein neuronales Netzwerk daraufhin trainiert, selbst unterscheiden zu können, ob ein Kraterkandidat auch wirklich ein Krater ist. Die Architektur des Netzwerkes ist in \figurename~\ref{fig:CLLD16_01} zu sehen. Zur Evaluierung der Ergebnisse wird hier das 10-fache Kreuzvalidierungsverfahren genutzt. Dies bedeutet, dass der Eingabedatensatz zehn-geteilt wird, und jeweils neun Teile zum trainieren und ein Teil zum Evaluieren genutzt wird. Das Ergebnis ist der Durchschnitt der jeweiligen F1-Scores.

\begin{figure}[H]
	\centering
	\includegraphics[width=.5\textwidth,keepaspectratio]{images/CLLD16_01.png}
	\caption{Die Architektur des Netzwerkes, aus \cite{cohen_16}}
	\label{fig:CLLD16_01}
\end{figure}

Der Unterschied zwischen dieser Methode und dem hier vorgestellten Ansatz besteht darin, dass in dieser Methode nur bewertet wird, ob Kraterkandidaten wirkliche Krater sind oder nicht, während hier ein Ansatz entwickelt wird, der aus einer kompletten Aufnahme der Marsoberfläche einzelne Krater(kandidaten) erkennt.

\subsection{Vergleich der Methoden}
\label{ssec:vergleich}

Die drei genannten Algorithmen (Urbach '09 \cite{urbach_stepinski_2009}, Bandeira '10 \cite{bandeira_10} und Cohen '16 \cite{cohen_16}) wurden alle auf der selben Aufnahme der HRSC angewandt. Eine genauere Beschreibung und der Vergleich anhand dieser Aufnahme findet sich in Abschnitt~\ref{sec:vergleich}.


\section{Texturbasiertes Clustering von Bilddateien}
\label{sec:clustering}


\begin{wrapfigure}{o}{0.38\textwidth}
	\centering
	\includegraphics[width=0.37\textwidth,keepaspectratio]{images/gen/GEN_slic_crater.png}
	\captionsetup{format=plain}
	\caption{Ergbenis des SLIC-Algorithmus angewandt auf eine Krateraufnahme}
	\label{fig:slic_crater}
\end{wrapfigure}

Da die zu analysierenden Aufnahmen nur in Graustufen vorhanden sind, eignet sich eine farbbasierte Clustering-Methode nicht um diese zuverlässig zu clustern. Selbst wenn dieses mit auf die Helligkeitswerte der Eingabedatei angewandt wird, führt dies dazu, dass der Algorithmus das Bild nach den Helligkeitswerten segmentiert, und nicht wie gewünscht anhand ihrer Oberflächenstruktur. So ergibt ein Clustering des Kraters aus \figurename~\ref{fig:ex_crater} durch den SLIC-Algorithmus \cite{achanta_10} das in \figurename~\ref{fig:slic_crater} sichtbare Ergebnis.\footnote{SLIC-Implementierung: \textit{scikit-image}\\Parameter: \textit{compactness}=20, \textit{n\_segments}=30\\Cluster gefüllt mit ihrer jeweiligen Durchnittshelligkeit} Hier ist erkennbar, dass der Krater in jeweilige Licht- und Schattenregionen (bedingt durch den Lichteinfall im flachen Winkel) unterteilt wird. Dieses Phänomen wird sich zwar in \ref{sec:craterdetection} zu nutze gemacht, ist hier allerdings ungewollt.

Wenn nun der in Unterabschnitt~\ref{ssec:kanezaki} beschriebene Ansatz verfolgt wird, wird das neuronale Netz daraufhin trainiert, eine Aufnahme anhand ihrer Helligkeitsinformationen hin zu trainieren. Da dies nicht gewollt ist, wird statt einem farb-/helligkeitsbasierten Clusteringalgorithmus wie SLIC ein texturbasiertes Clustering genutzt.

Eine geeignete Methode wird in \cite{jain_91} beschrieben: In dieser Methode wird eine Reihe von Gabor-Filtern dazu benutzt, die Textur des Bildes zu analysieren. Dieser Prozess verläuft wie folgt:

\begin{wrapfigure}{o}{0.5\textwidth}
	\centering
	\includegraphics[width=0.6\textwidth,keepaspectratio]{images/gen/GEN_tsugf_filterbank.png}
	\captionsetup{format=plain}
	\caption{Zum texturbasierten Clustering genutze Filterbank}
	\label{fig:tsugf_filters}
\end{wrapfigure}

 %TODO Was ist gabor filter
Zuerst wird eine reihe von Gabor-Filtern erstellt. Ein Beispiel, welches nach der originalen Ausarbeitung nachgestellt wurde, findet sich in \figurename~\ref{fig:tsugf_filters}. Es gilt zu beachten dass jeder Filter in mehrmals in unterschiedlichen Größen erstellt wird.

Diese werden anschließend über das in den Unterabschnitten~\ref{ssec:conv} und \ref{ssec:convlayer} beschriebene Konvolutionsverfahren angewandt. Dieser Vorgang resultiert in einem Datenwürfel, bei welchem die ersten beiden Dimensionen gleich der Höhe und breite der Eingabebilddatei sind, und die dritte Dimension gleich der Anzahl der genutzen Filter ist. Somit enthält jede Schicht des Würfels Informationen darüber, wie sehr und wo im Bild das Muster der jeweiligen Filterbank \enquote{erkannt} wird. Dies ist in \figurename~\ref{fig:tsugf_101027_raw} sichtbar.

\begin{figure}[H]
	\begin{subfigure}{0.328\textwidth}
		\centering
		\includegraphics[width=\textwidth,keepaspectratio]{images/bsd/101027.jpg}
		\captionsetup{format=plain}
		\caption{}
		\label{fig:bsd_101027}
	\end{subfigure}
	\begin{subfigure}{0.328\textwidth}
		\centering
		\includegraphics[width=\textwidth,keepaspectratio]{images/gen/GEN_tsugf_filterbank_101027_1.png}
		\caption{}
	\end{subfigure}
	\begin{subfigure}{0.328\textwidth}
		\centering
		\includegraphics[width=\textwidth,keepaspectratio]{images/gen/GEN_tsugf_filterbank_101027_2.png}
		\caption{}
	\end{subfigure}
	\begin{subfigure}{0.328\textwidth}
		\centering
		\includegraphics[width=\textwidth,keepaspectratio]{images/gen/GEN_tsugf_filterbank_101027_3.png}
		\caption{}
	\end{subfigure}
	\begin{subfigure}{0.328\textwidth}
		\centering
		\includegraphics[width=\textwidth,keepaspectratio]{images/gen/GEN_tsugf_filterbank_101027_4.png}
		\caption{}
	\end{subfigure}
	\caption{Ergebnisse (b-e) der Konvolution des Beispielbildes (a, aus \cite{bsd500}) mit den jeweiligen Filtern}
	\label{fig:tsugf_101027_raw}
\end{figure}

Anschließend wird der k-Means-Algorithmus auf diesen Datenwürfel angewandt: Dieser teilt eine beliebige Anzahl von Messpunkten (in diesem Fall je ein Vektor pro Pixel) in eine vorher festgelegte Menge an Clustern ein. Es werden also in dieser Anwendung Messpunkte/Pixel mit ähnlichen Texturen in Cluster zusammengefasst.


In der Praxis sind für die erfolgreiche Anwendung dieser Methode allerdings noch einige Optimierungen notwendig:

\begin{itemize}
	\item Räumlicher Bezug:\\
Damit diese Cluster eine (bessere) räumliche Beziehung zueinander haben, wird zu den Merkmalsdimensionen je eine Schicht hinzugefügt, welche ausschließlich mit den X-Koordinaten der jeweiligen Pixel gefüllt ist. Selbiges geschieht für die jeweiligen Y-Koordinaten. Da diese vom k-Means Algorithmus auch zusammen geclustert werden, entsteht ein örtlicher Bezug unter den Clustern.
	\item Weichzeichnung:\\
Da die Anwendung des Konvolutionsverfahrens in gewissen Fällen zu starken 
\end{itemize}
