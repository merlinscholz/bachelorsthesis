\chapter{Fazit}
\label{chap:fazit}

\section{Zusammenfassung}

In dieser Arbeit wurde auf einen Algorithmus zur Bildsegmentierung aus \cite{kanezaki_18} aufgebaut, um diesen so zu optimieren, dass dieser ein domänenspezifisches Problem löst. Dieses Problemstellung besteht daraus, fotografische Aufnahmen der Marsoberfläche anhand ihrer Merkmale in unterschiedliche Segmente zu klassifizieren.

Wie bei vielen aktuellen Segmentierungsproblemen wird zur Lösung ein konvolutionelles neuronales Netzwerk zur Hilfe gezogen. Diese zeigten zwar in vielen Anwendungsbereichen großen Erfolg, ihre Anwendung benötigt aber meistens einen Trainingsdatensatz, dieser ist für die Marsoberfläche jedoch nicht vorhanden. Es existieren zwar einige Datensätze und neuronale Netze zur Analyse der Marsoberfläche \cite{cohen_16}, diese konzentrieren sich allerdings fast ausschließlich auf die Kratererkennung. Stattdessen soll das Netzwerk anhand einer weiteren Clusteringmethode lernen, nach welchen Kriterien es das Eingabebild segmentieren soll.

\paragraph{Initialisierung} Diese Clusteringmethode war im originalen Algorithmus nach \cite{kanezaki_18} noch der SLIC-Algorithmus \cite{achanta_10}, dieser eignet sich nicht zur Anwendung in der hier beschriebenen Domäne, da er ausschließlich anhand der Koordinaten und Farbwerte eines Pixels entscheidet, mit welchen weiteren Pixeln dieser in ein Cluster zusammengefügt wird (\vgl Unterabschnitt~\ref{sec:initialization}). In dieser Arbeit wurde die Nutzung eines alternativen Clusterings zur Initialisierung untersucht, welches sich besser zur Erstellung von texturbasierten Clusterings eignet. Dabei wurde auf das texturbasierte Clustering mithilfe von Gabor-Filtern \cite{jain_91} genauer eingegangen, und für dieses eine geeignete Filterbank und die restlichen Parameter ausgewählt.

\paragraph{Netzwerkarchitektur} Obwohl die Netzwerkarchitektur aus der ursprünglichen Ausarbeitung \cite{kanezaki_18} bereits gute Ergebnisse erzielt hat, wurde versucht, diese weiter zu optimieren. Aus diesem Grund wurden Pooling-Schichten, Fully-Connected-Layers, alternative Abbruchkriterien und weitere Aktivierungsfunktionen daraufhin überprüft, ob sie diese Ergebnisse noch weiter verbessern können. Schlussendlich wurde neben kleineren Hyperparameter-Änderungen nur das Abbruchkriterium ersetzt. Ein Problem bestand darin, dass das originale Abbruchkriterium eine feste Anzahl an Segmenten benötigt hat. Da sämtliche Eingabebilder aber jeweils eine unterschiedliche Anzahl an Merkmalen aufweisen, war diese Lösung suboptimal. Für alternative Abbruchkriterien kamen unterschiedlichste Metriken in Frage, zu den besten Resultaten führt allerdings das Unterschreiten eines Grenzwertes für die Ableitung einer Annäherung an die Verlustfunktion.

\section{Fazit}

In dieser Arbeit wurde erfolgreich ein Algorithmus entwickelt, welcher Aufnahemn der Marsoberfläche anhand ihrer Oberflächenmerkmale, welche durch die jeweilige Textur erkannt werden, segmentiert. Dabei gilt es allerdings zu beachten, dass der Algorithmus in seiner derzeitigen Form nicht direkt auf allen Eingabeaufnahmen optimale Ergebnisse liefert: Während auf dem Datensatz der Context Camera des Mars Reconnaisance Orbiters (\vgl Unterabschnitt~\ref{ssec:mars_images}) viele gute Segmentierungen produziert wurden, verlief die Analyse der Oberfläche auf den Referenzaufnahmen des \textit{Robbins Crater Dataset} \cite{robbins_12} weniger erfolgreich, dort wurden hauptsächlich Krater erkannt (\vgl~Unterabschnitt\ref{ssec:discussion_domain}).

Obwohl der Algorithmus ursprünglich zur Anwendung auf Marsaufnahmen gedacht war, lässt dieser sich auch in weiteren Anwendungsgebieten einsetzten: So wurden \bspw unerwartet gute Ergebnisse bei der Anwendung auf den BSDS-500-Datensatz \cite{bsd500} erzielt, welcher alltägliche Fotografien beinhaltet. Ein weiterer Pluspunkt besteht daraus, dass durch die Tatsache, dass der Algorithmus unüberwacht operiert, er auch bei Segmentierungsproblemen eingesetzt werden kann, bei denen keine Ground Truth existiert. Ein Nachteil gegenüber bereits vorhandener, klassischer Segmentierungsalgorithmen besteht allerdings in der Performance: Durch eine durchschnittliche Rechenzeit von etwa einer Minute pro Aufnahme eignet er sich nicht in Anwendungsgebieten, in denen Echtzeitergebnisse von Nöten sind.

\paragraph{Probleme} Die erste Hürde bei der Entwicklung dieser Methode zur Bildsegmentierung trat relativ früh auf, bevor ein neuer Initialisierungsalgorithmus eingeführt wurde. Dort wurde lange überlegt, wie dem Netzwerk am besten beigebracht werden kann, anhand der Textur zu segmentieren. Einige Lösungsansätze bestanden daraus, den Mean-Shift-Algorithmus auf die Eingabedaten anzuwenden oder die Aktivierungen der jeweiligen Filter der Filterbänke direkt an das neuronale Netzwerk weiterzureichen, dies führte allerdings zu keinen brauchbaren Resultaten. Die schlussendlich vorgestellte, unerwartet einfache Lösung, den k-Means Algorithmus auf die Filterbankresultate anzuwenden wurde erst relativ spät in der Entwicklung dieser Arbeit weiter erforscht.

Aber auch mit dieser Initialisierung bestand das Problem weiterhin, dass das neuronale Netzwerk eine Segmentierung erstellt, welche sich zu stark nach den Helligkeitswerten der Eingabe richtet. Ein wichtiger Bestandteil zur Lösung dieses wurde in Unterabschnitt~\ref{ssec:initialization_number_of_segments} aufgeführt. Bies dieser Parameter verändert wurde entsprach die Anzahl der Initialisierungscluster wie in der originalen Arbeit \cite{kanezaki_18} gleich der Anzahl der Merkmalsebenen im neuronalen Netz.

Das letzte größere Problem bei der eigentlichen Entwicklung des Algorithmus bestand wie bereits beschrieben aus der Suche nach einem geeigneten Abbruchkriterium. Nachdem mehrere Metriken, wie die Anzahl der generierten Segmente oder der direkten Verlustfunktion untersucht wurden, ist aufgefallen, dass die Verlustfunktion sich immer an einen Wert anzunähern scheint, bloß ist dieser von Aufnahme zu Aufnahme unterschiedlich. Außerdem verläuft die Verlustfunktion sehr instabil, wie in Unterabschnitt~\ref{ssec:exp_stoppingcriteria} aufgezeigt wird. Da diese zu instabil (und diskret statt stetig) verläuft, war es nicht direkt möglich, diese Funktion abzuleiten, um schlussendlich das Überschreiten eines Grenzwertes der Ableitung als Abbruchkriterium zu nutzen. Abhilfe schaffte an dieser Stelle eine Approximation der Verlustfunktion durch die Funktion $f(x)=a\frac{1}{x}+b$. Mithilfe von dessen Ableitung wurde ein geeignetes Abbruchkriterium geschaffen.

Eine Herausforderung bei der Evaluation des Algorithmus stellte der Mangel an verwandten Arbeiten und Datensätzen dar: Für alltägliche Anwendungsbereiche sind selbstverständlich viele Datensätze verfügbar, wie das genutzt BSDS-500-Datenset, oder auch \textit{Common Objects in Context} \cite{lin_14}. Für den Mars allerdings existiert kein auch nur teilweise segmentierter Datensatz, und auch jene zur Kratererkennung sind selten und schwer zu finden. Daher wurde in dieser Arbeit eine Methode zum Post-Processing vorgestellt, mithilfe aus der Segmentierung einzelne Krater extrahiert werden konnten (\vgl Unterabschnitt~\ref{ssec:evaluation_domain}). Diese konnten anschließend mit Datensätzen verglichen werden, welche nur Informationen über Krater katalogisiert haben, auch wenn so keine optimalen Ergebnisse produziert werden konnten, da der Algorithmus nicht explizit auf diese Aufgabenstellung hin angepasst wurde.

\section{Zukünftige Arbeiten}

Diese Arbeit soll als Grundlage für weitere Forschung dienen. So wurden einige in der Arbeit beschriebene Probleme \bzw deren Lösungsansätze noch nicht vollständig evaluiert. Ein Beispiel dafür liefert die Nutzung von dynamischen Filtergrößen in der Initialisierung (\vgl Unterabschnitt~\ref{ssec:discussion_allgemein}). Eine weitere Verbesserungsmöglichkeit besteht aus der Nutzung bereits erprobter Netzwerkarchitekturen zur Bildsegmentierung, wie \bspw \cite{ronneberger_15}.

In Unterabschnitt~\ref{ssec:discussion_allgemein} wird des Weiteren die Nutzung eines Orakels zur Generierung optimaler Parameter (insbesondere die Filtergröße) für die Initialisierung eines jeden Eingabebildes erläutert, dieser Ansatz wurde sich bereits in \cite{arbelaez_10} zu Nutze gemacht und lässt sich eventuell auch auf den hier erarbeiteten Algorithmus übertragen.

Zukünftige Arbeiten könnten den vorgestellten Ansatz auch so adaptieren, als dass dieser in einer komplett unterschiedlichen Domäne Anwendung finden kann. In Unterabschnitt~\ref{ssec:discussion_allgemein} wurde beschrieben, dass sich diese Methode zur Bildsegmentierung hervorragend im medizinischen Bereich einsetzten lassen müsste: Auch dort gilt es häufig, Aufnahmen anhand ihrer Textur zu segmentieren, und auch dort sind oftmals keine Ground Truths vorhanden, mit denen ein überwachtes neuronales Netzwerk diesen Prozess erlernen könnte.

Ein letzter Punkt, der in dieser Arbeit übersprungen wurde, besteht daraus, eine große Aufnahme auf ressourcenbeschränkten System erfolgreich zu segmentieren. Die derzeitige Lösung besteht daraus, die Eingabedatei in mehrere Unteraufnahmen einzuteilen, und diese komplett unabhängig voneinander zu analysieren. Dieser Ansatz lässt allerdings zu wünschen übrig, da so Flächen, welche diese arbiträr gesetzten Grenzen überschreiten, nicht als eine zusammengehörige Region gekennzeichnet werden können. An dieser Stelle könnte ein angepasstes Sliding-Window-Verfahren hilfreich sein.