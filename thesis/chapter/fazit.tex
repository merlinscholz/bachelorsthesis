\chapter{Fazit}
\label{chap:fazit}

\section{Zusammenfassung}

In dieser Arbeit wurde auf einen Algorithmus zur Bildsegmentierung aus \cite{kanezaki_18} aufgebaut, um diesen so zu optimieren, dass dieser ein domänenspezifisches Problem löst. Dieses Problem besteht daraus, fotografische Aufnahmen der Marsoberfläche anhand ihrer Merkmale in unterschiedliche Segmente aufzuteilen.

Wie bei vielen aktuellen Segmentierungsproblemen wird zur Lösung ein konvolutionelles neuronales Netzwerk zur Hilfe gezogen. Diese zeigten zwar in vielen Anwendungsbereichen großen Erfolg, ihre Anwendung benötigt aber meistens einen Trainingsdatensatz, dieser ist für die Marsoberfläche jedoch nicht vorhanden. Es existieren zwar einige Datensätze und neuronale Netze zur Analyse der Marsoberfläche \cite{cohen_16}, diese konzentrieren sich allerdings fast ausschließlich auf die Kratererkennung. Stattdessen soll das Netzwerk anhand einer weiteren Clusteringmethode lernen, nach welchen Kriterien es das Eingabebild segmentieren soll.

\paragraph{Initialisierung} Diese Clusteringmethode war im originalen Algorithmus nach \cite{kanezaki_18} noch der SLIC-Algorithmus \cite{achanta_10}, dieser eignet sich nicht zur Anwendung in der hier beschriebenen Domäne, da er ausschließlich anhand der Koordinaten und Farbwerte eines Pixels entscheidet, mit welchen weiteren Pixeln dieser in ein Cluster zusammengefügt wird. In dieser Arbeit wurde die Nutzung eines alternativen Clusterings zur Initialisierung untersucht, welches sich besser zur Erstellung von texturbasierten Clusterings eignet. Dabei wurde auf das texturbasierte Clustering mithilfe von Gabor-Filtern \cite{jain_91} eingegangen, und für dieses eine geeignete Filterbank und die restlichen Parameter ausgewählt.

\paragraph{Netzwerkarchitektur} Obwohl die Netzwerkarchitektur aus der ursprünglichen Ausarbeitung \cite{kanezaki_18} bereits gute Ergebnisse erzielt hat, wurde versucht, diese weiter zu optimieren. Aus diesem Grund wurden Pooling-Schichten, Fully-Connected-Layers, alternative Abbruchkriterien und weitere Aktivierungsfunktionen daraufhin überprüft, ob sie diese Ergebnisse noch weiter verbessern können. Schlussendlich wurde neben kleineren Hyperparameter-Änderungen nur das Abbruchkriterium ersetzt. Ein Problem bestand darin, dass das originale Abbruchkriterium eine feste Anzahl an Segmenten benötigt hat. Da sämtliche Eingabebilder aber jeweils eine unterschiedliche Anzahl an Merkmalen aufweisen, war diese lösung suboptimal. Für alternative Abbruchkriterien kamen unterschiedlichste Metriken in Frage, zu den besten Resultaten führt allerdings das Unterschreiten eines Grenzwertes für die Ableitung einer Annäherung an die Verlustfunktion.

\section{Fazit}

Obwohl der Algorithmus ursprünglich zur Anwendung auf Marsaufnahmen gedacht war, lässt dieser sich auch in weiteren Anwendungsgebieten einsetzten: So wurden \bspw unerwartet gute Ergebnisse bei der Anwendung auf den BSDS-500-Datensatz \cite{bsd500} erzielt, welcher alltägliche Fotografien beinhaltet. Ein weiterer Pluspunkt besteht daraus, dass durch die Tatsache, dass der Algorithmus unüberwacht operiert, er auch bei Segmentierungsproblemen eingesetzt werden kann, bei denen keine Ground Truth existiert. Ein Nachteil gegenüber bereits vorhandener, klassischer Segmentierungsalgorithmen besteht allerdings in der Performance: Durch eine durchschnittliche Rechenzeit von etwa einer Minute pro Aufnahme eignet er sich nicht in Anwendungsgebieten, in denen Echtzeitergebnisse von Nöten sind.

\paragraph{Probleme} Eines der größten Probleme bei der Entwicklung und Evaluation des Algorithmus bestand aus dem Mangel an verwandten Arbeiten und Datensätzen: Für alltägliche Anwendungsbereiche sind selbstverständlich viele Datensätze verfügbar, wie das genutzt BSDS-500-Datenset, oder auch \textit{Common Objects in Context} \cite{lin_14}. Für den Mars allerdings existiert kein auch nur teilweise segmentierter Datensatz, und auch jene zur Kratererkennung sind selten und schwer zu finden. Daher wurde in dieser Arbeit eine Methode zum Post-Processing vorgestellt, mithilfe aus der Segmentierung einzelne Krater extrahiert werden konnten (\vgl Unterabschnitt~\ref{ssec:evaluation_domain}). Diese konnten anschließend mit Datensätzen verglichen werden, welche nur Informationen über Krater katalogisiert haben.



\section{Zukünftige Arbeiten}

Diese Arbeit soll als Grundlage für weitere Forschung dienen. So wurden einige in der Arbeit beschriebene Probleme \bzw deren Lösungsansätze noch nicht vollständig evaluiert. Ein Beispiel dafür liefert die Nutzung von dynamischen Filtergrößen in der Initialisierung (\vgl Unterabschnitt~\ref{ssec:discussion_allgemein}). Eine weitere Verbesserungsmöglichkeit besteht aus der Nutzung bereits erprobter Netzwerkarchitekturen zur Bildsegmentierung, wie \bspw \cite{ronneberger_15}.

Zukünftige Arbeiten könnten sich den vorgestellten Ansatz auch so adaptieren, als dass dieser in einer komplett unterschiedlichen Domäne Anwendung finden kann. In Unterabschnitt~\ref{ssec:discussion_allgemein} wurde 